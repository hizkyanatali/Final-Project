{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.metrics import recall_score, precision_score, confusion_matrix, classification_report, roc_auc_score\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/volodymyrgavrysh/bank-marketing-campaigns-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features Description\n",
    "\n",
    "### bank client data:\n",
    "- __age__\n",
    "- __job__ : type of job (categorical: \"admin.\",\"blue-collar\",\"entrepreneur\",...,\"unknown\")\n",
    "- __marital__ : marital status (categorical: \"divorced\",\"married\",\"single\",\"unknown\")\n",
    "- __education__ : (categorical: \"illiterate\",...,\"university.degree\",\"unknown\")\n",
    "- __default__: has credit in default? (categorical: \"no\",\"yes\",\"unknown\")\n",
    "- __housing__: has housing loan? (categorical: \"no\",\"yes\",\"unknown\")\n",
    "- __loan__: has personal loan? (categorical: \"no\",\"yes\",\"unknown\")\n",
    "    \n",
    "### related with the last contact of the current campaign:\n",
    "- __contact__: contact communication type (categorical: \"cellular\",\"telephone\")\n",
    "- __month__: last contact month of year (categorical: \"jan\", …, \"nov\", \"dec\")\n",
    "- __dayofweek__: last contact day of the week (categorical: \"mon\",\"tue\",...)\n",
    "- __duration__: last contact duration, in seconds (numeric).\n",
    "    - __Important note__: this attribute highly affects the output target (e.g., if duration=0 then y=\"no\"). , Can not get this feature before the campaign\n",
    "\n",
    "### other attributes:\n",
    "- __campaign__: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n",
    "    - __Important note__: Can not get this feature before the campaign\n",
    "- __pdays__: number of days that passed by after the client was last contacted from a previous campaign (numeric; 999 means client was not previously contacted)\n",
    "- __previous__: number of contacts performed before this campaign and for this client (numeric)\n",
    "- __poutcome__: outcome of the previous marketing campaign (categorical: \"failure\",\"nonexistent\",\"success\")\n",
    "\n",
    "### social and economic context attributes\n",
    "- __emp.var.rate__: employment variation rate - quarterly indicator (numeric)\n",
    "- __cons.price.idx__: consumer price index - monthly indicator (changes in the price level of a weighted average __market basket__ of consumer goods and services purchased by households, affect inflation (numeric))\n",
    "- __cons.conf.idx__: consumer confidence index - monthly indicator (degree of __consumers optimism__ are expressing through their activities of savings and spending. affect consumer behavior (numeric))\n",
    "- __euribor3m__: euribor 3 month rate - daily indicator (Euribor (euro interbank offered rate) (numeric))\n",
    "- __nr.employed__: number of employees - quarterly indicator (Number of employed persons for a quarter (numeric))\n",
    "\n",
    "### Output variable (desired target):\n",
    "- __y__ - has the client subscribed a term deposit? (binary: \"yes\",\"no\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GOALS \n",
    "\n",
    "1. __Reduce False Positive__ \n",
    "2. __Increase Precision for y='yes'__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>...</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic.6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high.school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic.4y       no      no   no  telephone   \n",
       "1   57   services  married  high.school  unknown      no   no  telephone   \n",
       "2   37   services  married  high.school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic.6y       no      no   no  telephone   \n",
       "4   56   services  married  high.school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week  ...  campaign  pdays  previous     poutcome emp.var.rate  \\\n",
       "0   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "1   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "2   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "3   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "4   may         mon  ...         1    999         0  nonexistent          1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0          93.994          -36.4      4.857       5191.0  no  \n",
       "1          93.994          -36.4      4.857       5191.0  no  \n",
       "2          93.994          -36.4      4.857       5191.0  no  \n",
       "3          93.994          -36.4      4.857       5191.0  no  \n",
       "4          93.994          -36.4      4.857       5191.0  no  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Read data from csv\n",
    "\n",
    "df = pd.read_csv('bank-additional-full.csv', sep=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change value format in education column\n",
    "\n",
    "df.education = df.education.apply(lambda x : x.replace(\".\", \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns that we can not get if we use the model before the campaign\n",
    "\n",
    "df_1 = df.drop(columns=['duration', 'campaign'\n",
    "#                         , 'emp.var.rate', 'nr.employed', 'day_of_week', 'housing'\n",
    "                       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>housemaid</td>\n",
       "      <td>married</td>\n",
       "      <td>basic 4y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high school</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high school</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>basic 6y</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>56</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>high school</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age        job  marital    education  default housing loan    contact  \\\n",
       "0   56  housemaid  married     basic 4y       no      no   no  telephone   \n",
       "1   57   services  married  high school  unknown      no   no  telephone   \n",
       "2   37   services  married  high school       no     yes   no  telephone   \n",
       "3   40     admin.  married     basic 6y       no      no   no  telephone   \n",
       "4   56   services  married  high school       no      no  yes  telephone   \n",
       "\n",
       "  month day_of_week  pdays  previous     poutcome  emp.var.rate  \\\n",
       "0   may         mon    999         0  nonexistent           1.1   \n",
       "1   may         mon    999         0  nonexistent           1.1   \n",
       "2   may         mon    999         0  nonexistent           1.1   \n",
       "3   may         mon    999         0  nonexistent           1.1   \n",
       "4   may         mon    999         0  nonexistent           1.1   \n",
       "\n",
       "   cons.price.idx  cons.conf.idx  euribor3m  nr.employed   y  \n",
       "0          93.994          -36.4      4.857       5191.0  no  \n",
       "1          93.994          -36.4      4.857       5191.0  no  \n",
       "2          93.994          -36.4      4.857       5191.0  no  \n",
       "3          93.994          -36.4      4.857       5191.0  no  \n",
       "4          93.994          -36.4      4.857       5191.0  no  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing dataframe\n",
    "\n",
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change target column values to numeric value\n",
    "\n",
    "df_1['y'][df_1['y'] == 'no'] = 0\n",
    "df_1['y'][df_1['y'] == 'yes'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    36548\n",
       "1     4640\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the value in target columns\n",
    "\n",
    "df_1['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the value's type into integer\n",
    "\n",
    "df_1['y'] = df_1['y'].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Imbalance Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    88.73\n",
       "1    11.27\n",
       "Name: y, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check distribution of the target column values in percentage\n",
    "\n",
    "round(df_1['y'].value_counts()/len(df_1)*100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Engineering\n",
    "\n",
    "Do the __Scaling__ for numerical columns (Robust Scaling) in Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. __Label Encoding__ for education column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label encoding using map\n",
    "\n",
    "df_1['education'] = df_1['education'].map({'basic 4y':1\n",
    "                              , 'basic 6y':2\n",
    "                              , 'basic 9y' :3\n",
    "                              , \"high school\":4\n",
    "                              , \"university degree\":5\n",
    "                              , 'professional course':6\n",
    "                              , 'illiterate':0\n",
    "                              , 'unknown':0\n",
    "                             })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate the columns into X and Y\n",
    "\n",
    "X = df_1.drop(columns='y')\n",
    "y = df_1['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data splitting\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Over Sampling\n",
    "\n",
    "Do oversampling method (because the data is imbalance) __only__ for train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make data frame from train data\n",
    "\n",
    "df_train = pd.concat([X_train,y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>month</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25611</th>\n",
       "      <td>49</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>3</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>nov</td>\n",
       "      <td>wed</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>93.200</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>4.120</td>\n",
       "      <td>5195.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26010</th>\n",
       "      <td>37</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>5</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>nov</td>\n",
       "      <td>wed</td>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>93.200</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>4.120</td>\n",
       "      <td>5195.8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40194</th>\n",
       "      <td>78</td>\n",
       "      <td>retired</td>\n",
       "      <td>married</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jul</td>\n",
       "      <td>mon</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>94.215</td>\n",
       "      <td>-40.3</td>\n",
       "      <td>0.870</td>\n",
       "      <td>4991.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>36</td>\n",
       "      <td>admin.</td>\n",
       "      <td>married</td>\n",
       "      <td>5</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>telephone</td>\n",
       "      <td>may</td>\n",
       "      <td>mon</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>1.1</td>\n",
       "      <td>93.994</td>\n",
       "      <td>-36.4</td>\n",
       "      <td>4.857</td>\n",
       "      <td>5191.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36344</th>\n",
       "      <td>59</td>\n",
       "      <td>retired</td>\n",
       "      <td>divorced</td>\n",
       "      <td>5</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>jun</td>\n",
       "      <td>tue</td>\n",
       "      <td>999</td>\n",
       "      <td>0</td>\n",
       "      <td>nonexistent</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>92.963</td>\n",
       "      <td>-40.8</td>\n",
       "      <td>1.262</td>\n",
       "      <td>5076.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       age           job   marital  education  default housing loan  \\\n",
       "25611   49   blue-collar   married          3  unknown      no   no   \n",
       "26010   37  entrepreneur   married          5       no      no   no   \n",
       "40194   78       retired   married          1       no      no   no   \n",
       "297     36        admin.   married          5       no     yes   no   \n",
       "36344   59       retired  divorced          5       no      no   no   \n",
       "\n",
       "         contact month day_of_week  pdays  previous     poutcome  \\\n",
       "25611   cellular   nov         wed    999         0  nonexistent   \n",
       "26010  telephone   nov         wed    999         1      failure   \n",
       "40194   cellular   jul         mon    999         0  nonexistent   \n",
       "297    telephone   may         mon    999         0  nonexistent   \n",
       "36344   cellular   jun         tue    999         0  nonexistent   \n",
       "\n",
       "       emp.var.rate  cons.price.idx  cons.conf.idx  euribor3m  nr.employed  y  \n",
       "25611          -0.1          93.200          -42.0      4.120       5195.8  0  \n",
       "26010          -0.1          93.200          -42.0      4.120       5195.8  0  \n",
       "40194          -1.7          94.215          -40.3      0.870       4991.6  1  \n",
       "297             1.1          93.994          -36.4      4.857       5191.0  0  \n",
       "36344          -2.9          92.963          -40.8      1.262       5076.2  0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show df_train\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29238\n",
       "1     3712\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check data imbalance in df_train\n",
    "\n",
    "df_train['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_default = df_train[df_train['y'] == 0] # majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "default = df_train[df_train['y'] == 1] # minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversampling/Upsampling with resample method\n",
    "\n",
    "default_oversample = resample(default, \n",
    "                           replace = True, \n",
    "                           n_samples = len(non_default),\n",
    "                           random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make data frame for oversampling data\n",
    "\n",
    "df_OverSample= pd.concat([non_default, default_oversample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    29238\n",
       "0    29238\n",
       "Name: y, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking data imbalance in df_oversample\n",
    "\n",
    "df_OverSample['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data X and Y for Oversample Data fram\n",
    "\n",
    "X_train_OS = df_OverSample.drop(columns='y')\n",
    "y_train_OS = df_OverSample['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELLING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "we used pipeline method for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the numeric columns and categoric columns from the dataset\n",
    "\n",
    "num_columns = ['age', 'education', 'pdays', 'previous', 'cons.price.idx', 'cons.conf.idx', 'euribor3m'\n",
    "               , 'nr.employed', 'emp.var.rate'\n",
    "              ]\n",
    "\n",
    "cat_columns = [i for i in df_1.columns if (i not in num_columns) & (i!='y')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pipeline and model\n",
    "\n",
    "numeric_pipeline = Pipeline([\n",
    "    ('scaler', RobustScaler()),\n",
    "#     ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "#     ('power', PowerTransformer(method='yeo-johnson'))\n",
    "])\n",
    "\n",
    "categoric_pipeline = Pipeline([\n",
    "    ('encoder', OneHotEncoder())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('numeric', numeric_pipeline, num_columns),\n",
    "    ('categorical', categoric_pipeline, cat_columns)\n",
    "])\n",
    "\n",
    "pipe_LR = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('algo', LogisticRegression())\n",
    "])\n",
    "\n",
    "pipe_KNN = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('algo', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "pipe_SVM = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('algo', SVC(max_iter=600))\n",
    "])\n",
    "\n",
    "pipe_DT = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('algo', DecisionTreeClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "pipe_RF = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('algo', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "pipe_XGB = Pipeline([\n",
    "    ('prep', preprocessor),\n",
    "    ('algo', XGBClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Def Function for Evaluation Metrix\n",
    "\n",
    "create a `def` function for evaluation metrix after modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def function for each model evaluation matrix\n",
    "\n",
    "def conf_mat (Model, X_train, X_test, y_train, y_test,Nama):\n",
    "    y_pred_test = Model.predict(X_test)\n",
    "    cm_test = confusion_matrix(y_test, y_pred_test, labels=[1,0])\n",
    "    df_test = pd.DataFrame(cm_test, index = ['Akt1', 'Akt0'], columns=['Pred1', 'Pred0'])\n",
    "    print( 'Classification report data TEST ' + Nama + '\\n\\n', classification_report(y_test, y_pred_test))\n",
    "    print('\\nROC AUC test :', round(roc_auc_score(y_test, y_pred_test), 2), '\\n')\n",
    "    print('\\nConfusion matrix data test ' + Nama + '\\n\\n')\n",
    "    print(df_test)\n",
    "    print('='*100)\n",
    "    y_pred_train = Model.predict(X_train)\n",
    "    cm_train = confusion_matrix(y_train, y_pred_train, labels=[1,0])\n",
    "    df_train = pd.DataFrame(cm_train, index = ['Akt1', 'Akt0'], columns=['Pred1', 'Pred0'])\n",
    "    print( 'Classification report data TRAIN ' + Nama + '\\n\\n', classification_report(y_train, y_pred_train))\n",
    "    print('\\nROC AUC train :', round(roc_auc_score(y_train, y_pred_train), 2), '\\n')\n",
    "    print('\\nConfusion matrix data train ' + Nama + '\\n\\n')\n",
    "    print(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def function to compare the evaluation matrix for some models\n",
    "\n",
    "def prec_rec (Model, X_test, y_test, Nama):\n",
    "    data = {}\n",
    "    prec = []\n",
    "    rec = []\n",
    "    for i in Model :\n",
    "        y_pred_ts = i.predict(X_test)\n",
    "        precision = precision_score(y_test, y_pred_ts)\n",
    "        recall = recall_score(y_test, y_pred_ts)\n",
    "        prec.append(precision)\n",
    "        rec.append(recall)\n",
    "    for j in range (len(Nama)):\n",
    "        data[Nama[j]] = [prec[j], rec[j]]\n",
    "    \n",
    "    df = pd.DataFrame(data, index=['Precison', 'Recall'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Logistic Regression__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('prep',\n",
       "                 ColumnTransformer(transformers=[('numeric',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   RobustScaler())]),\n",
       "                                                  ['age', 'education', 'pdays',\n",
       "                                                   'previous', 'cons.price.idx',\n",
       "                                                   'cons.conf.idx', 'euribor3m',\n",
       "                                                   'nr.employed',\n",
       "                                                   'emp.var.rate']),\n",
       "                                                 ('categorical',\n",
       "                                                  Pipeline(steps=[('encoder',\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  ['job', 'marital', 'default',\n",
       "                                                   'housing', 'loan', 'contact',\n",
       "                                                   'month', 'day_of_week',\n",
       "                                                   'poutcome'])])),\n",
       "                ('algo', LogisticRegression())])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic regression base model fitting\n",
    "\n",
    "pipe_LR.fit(X_train_OS, y_train_OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report data TEST LR Base\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.85      0.90      7310\n",
      "           1       0.36      0.65      0.46       928\n",
      "\n",
      "    accuracy                           0.83      8238\n",
      "   macro avg       0.65      0.75      0.68      8238\n",
      "weighted avg       0.88      0.83      0.85      8238\n",
      "\n",
      "\n",
      "ROC AUC test : 0.75 \n",
      "\n",
      "\n",
      "Confusion matrix data test LR Base\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1    599    329\n",
      "Akt0   1082   6228\n",
      "====================================================================================================\n",
      "Classification report data TRAIN LR Base\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.85      0.76     29238\n",
      "           1       0.80      0.62      0.70     29238\n",
      "\n",
      "    accuracy                           0.73     58476\n",
      "   macro avg       0.75      0.73      0.73     58476\n",
      "weighted avg       0.75      0.73      0.73     58476\n",
      "\n",
      "\n",
      "ROC AUC train : 0.73 \n",
      "\n",
      "\n",
      "Confusion matrix data train LR Base\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1  18136  11102\n",
      "Akt0   4411  24827\n"
     ]
    }
   ],
   "source": [
    "# evaluation matrix of Logistic regression base model\n",
    "\n",
    "conf_mat(pipe_LR, X_train_OS, X_test, y_train_OS, y_test, 'LR Base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__K-Nearest Neighbor__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('prep',\n",
       "                 ColumnTransformer(transformers=[('numeric',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   RobustScaler())]),\n",
       "                                                  ['age', 'education', 'pdays',\n",
       "                                                   'previous', 'cons.price.idx',\n",
       "                                                   'cons.conf.idx', 'euribor3m',\n",
       "                                                   'nr.employed',\n",
       "                                                   'emp.var.rate']),\n",
       "                                                 ('categorical',\n",
       "                                                  Pipeline(steps=[('encoder',\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  ['job', 'marital', 'default',\n",
       "                                                   'housing', 'loan', 'contact',\n",
       "                                                   'month', 'day_of_week',\n",
       "                                                   'poutcome'])])),\n",
       "                ('algo', KNeighborsClassifier())])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K-Nearest Neighbor base model fitting\n",
    "\n",
    "pipe_KNN.fit(X_train_OS, y_train_OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report data TEST KNN Base\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.81      0.87      7310\n",
      "           1       0.27      0.57      0.37       928\n",
      "\n",
      "    accuracy                           0.78      8238\n",
      "   macro avg       0.60      0.69      0.62      8238\n",
      "weighted avg       0.86      0.78      0.81      8238\n",
      "\n",
      "\n",
      "ROC AUC test : 0.69 \n",
      "\n",
      "\n",
      "Confusion matrix data test KNN Base\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1    531    397\n",
      "Akt0   1424   5886\n",
      "====================================================================================================\n",
      "Classification report data TRAIN KNN Base\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.92     29238\n",
      "           1       0.87      1.00      0.93     29238\n",
      "\n",
      "    accuracy                           0.93     58476\n",
      "   macro avg       0.93      0.93      0.93     58476\n",
      "weighted avg       0.93      0.93      0.93     58476\n",
      "\n",
      "\n",
      "ROC AUC train : 0.93 \n",
      "\n",
      "\n",
      "Confusion matrix data train KNN Base\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1  29115    123\n",
      "Akt0   4194  25044\n"
     ]
    }
   ],
   "source": [
    "# evaluation metrix of K-Nearest Neighbor base model\n",
    "\n",
    "conf_mat(pipe_KNN, X_train_OS, X_test, y_train_OS, y_test, 'KNN Base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Support Vector Machine__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('prep',\n",
       "                 ColumnTransformer(transformers=[('numeric',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   RobustScaler())]),\n",
       "                                                  ['age', 'education', 'pdays',\n",
       "                                                   'previous', 'cons.price.idx',\n",
       "                                                   'cons.conf.idx', 'euribor3m',\n",
       "                                                   'nr.employed',\n",
       "                                                   'emp.var.rate']),\n",
       "                                                 ('categorical',\n",
       "                                                  Pipeline(steps=[('encoder',\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  ['job', 'marital', 'default',\n",
       "                                                   'housing', 'loan', 'contact',\n",
       "                                                   'month', 'day_of_week',\n",
       "                                                   'poutcome'])])),\n",
       "                ('algo', SVC(max_iter=600))])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Support Vector Machine base model fitting\n",
    "\n",
    "pipe_SVM.fit(X_train_OS, y_train_OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report data TEST SVM Base\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.01      0.03      7310\n",
      "           1       0.09      0.80      0.17       928\n",
      "\n",
      "    accuracy                           0.10      8238\n",
      "   macro avg       0.22      0.41      0.10      8238\n",
      "weighted avg       0.32      0.10      0.04      8238\n",
      "\n",
      "\n",
      "ROC AUC test : 0.41 \n",
      "\n",
      "\n",
      "Confusion matrix data test SVM Base\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1    741    187\n",
      "Akt0   7208    102\n",
      "====================================================================================================\n",
      "Classification report data TRAIN SVM Base\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.02      0.02     29238\n",
      "           1       0.45      0.79      0.57     29238\n",
      "\n",
      "    accuracy                           0.40     58476\n",
      "   macro avg       0.26      0.40      0.30     58476\n",
      "weighted avg       0.26      0.40      0.30     58476\n",
      "\n",
      "\n",
      "ROC AUC train : 0.4 \n",
      "\n",
      "\n",
      "Confusion matrix data train SVM Base\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1  23095   6143\n",
      "Akt0  28792    446\n"
     ]
    }
   ],
   "source": [
    "# Evaluation Matrix of Support Vector Machine base model\n",
    "\n",
    "conf_mat(pipe_SVM, X_train_OS, X_test, y_train_OS, y_test, 'SVM Base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Decision Tree__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('prep',\n",
       "                 ColumnTransformer(transformers=[('numeric',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   RobustScaler())]),\n",
       "                                                  ['age', 'education', 'pdays',\n",
       "                                                   'previous', 'cons.price.idx',\n",
       "                                                   'cons.conf.idx', 'euribor3m',\n",
       "                                                   'nr.employed',\n",
       "                                                   'emp.var.rate']),\n",
       "                                                 ('categorical',\n",
       "                                                  Pipeline(steps=[('encoder',\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  ['job', 'marital', 'default',\n",
       "                                                   'housing', 'loan', 'contact',\n",
       "                                                   'month', 'day_of_week',\n",
       "                                                   'poutcome'])])),\n",
       "                ('algo', DecisionTreeClassifier(random_state=42))])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree base model fitting\n",
    "\n",
    "pipe_DT.fit(X_train_OS, y_train_OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report data TEST DT Over Sampling\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91      7310\n",
      "           1       0.31      0.36      0.33       928\n",
      "\n",
      "    accuracy                           0.84      8238\n",
      "   macro avg       0.61      0.63      0.62      8238\n",
      "weighted avg       0.85      0.84      0.84      8238\n",
      "\n",
      "\n",
      "ROC AUC test : 0.63 \n",
      "\n",
      "\n",
      "Confusion matrix data test DT Over Sampling\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1    331    597\n",
      "Akt0    750   6560\n",
      "====================================================================================================\n",
      "Classification report data TRAIN DT Over Sampling\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     29238\n",
      "           1       0.99      1.00      0.99     29238\n",
      "\n",
      "    accuracy                           0.99     58476\n",
      "   macro avg       0.99      0.99      0.99     58476\n",
      "weighted avg       0.99      0.99      0.99     58476\n",
      "\n",
      "\n",
      "ROC AUC train : 0.99 \n",
      "\n",
      "\n",
      "Confusion matrix data train DT Over Sampling\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1  29224     14\n",
      "Akt0    438  28800\n"
     ]
    }
   ],
   "source": [
    "# Evaluation Matrix of Decision Tree base model\n",
    "\n",
    "conf_mat(pipe_DT, X_train_OS, X_test, y_train_OS, y_test, 'DT Over Sampling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Random Forest__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('prep',\n",
       "                 ColumnTransformer(transformers=[('numeric',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   RobustScaler())]),\n",
       "                                                  ['age', 'education', 'pdays',\n",
       "                                                   'previous', 'cons.price.idx',\n",
       "                                                   'cons.conf.idx', 'euribor3m',\n",
       "                                                   'nr.employed',\n",
       "                                                   'emp.var.rate']),\n",
       "                                                 ('categorical',\n",
       "                                                  Pipeline(steps=[('encoder',\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  ['job', 'marital', 'default',\n",
       "                                                   'housing', 'loan', 'contact',\n",
       "                                                   'month', 'day_of_week',\n",
       "                                                   'poutcome'])])),\n",
       "                ('algo', RandomForestClassifier(random_state=42))])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest base model fitting\n",
    "\n",
    "pipe_RF.fit(X_train_OS, y_train_OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report data TEST RF Base\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93      7310\n",
      "           1       0.45      0.41      0.43       928\n",
      "\n",
      "    accuracy                           0.88      8238\n",
      "   macro avg       0.69      0.67      0.68      8238\n",
      "weighted avg       0.87      0.88      0.87      8238\n",
      "\n",
      "\n",
      "ROC AUC test : 0.67 \n",
      "\n",
      "\n",
      "Confusion matrix data test RF Base\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1    382    546\n",
      "Akt0    473   6837\n",
      "====================================================================================================\n",
      "Classification report data TRAIN RF Base\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     29238\n",
      "           1       0.99      1.00      0.99     29238\n",
      "\n",
      "    accuracy                           0.99     58476\n",
      "   macro avg       0.99      0.99      0.99     58476\n",
      "weighted avg       0.99      0.99      0.99     58476\n",
      "\n",
      "\n",
      "ROC AUC train : 0.99 \n",
      "\n",
      "\n",
      "Confusion matrix data train RF Base\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1  29228     10\n",
      "Akt0    442  28796\n"
     ]
    }
   ],
   "source": [
    "# Evaluation Matrix of Random Forest base model\n",
    "\n",
    "conf_mat(pipe_RF, X_train_OS, X_test, y_train_OS, y_test, 'RF Base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__XGBoost__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:54:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('prep',\n",
       "                 ColumnTransformer(transformers=[('numeric',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   RobustScaler())]),\n",
       "                                                  ['age', 'education', 'pdays',\n",
       "                                                   'previous', 'cons.price.idx',\n",
       "                                                   'cons.conf.idx', 'euribor3m',\n",
       "                                                   'nr.employed',\n",
       "                                                   'emp.var.rate']),\n",
       "                                                 ('categorical',\n",
       "                                                  Pipeline(steps=[('encoder',\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  ['job', 'marital', 'default',\n",
       "                                                   'housing', 'loan', 'contact',\n",
       "                                                   'month', 'd...\n",
       "                               colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "                               importance_type='gain',\n",
       "                               interaction_constraints='',\n",
       "                               learning_rate=0.300000012, max_delta_step=0,\n",
       "                               max_depth=6, min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=100,\n",
       "                               n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                               subsample=1, tree_method='exact',\n",
       "                               validate_parameters=1, verbosity=None))])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XGBoost base model fitting\n",
    "\n",
    "pipe_XGB.fit(X_train_OS, y_train_OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report data TEST XGB Base\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.88      0.91      7310\n",
      "           1       0.39      0.59      0.47       928\n",
      "\n",
      "    accuracy                           0.85      8238\n",
      "   macro avg       0.67      0.74      0.69      8238\n",
      "weighted avg       0.88      0.85      0.86      8238\n",
      "\n",
      "\n",
      "ROC AUC test : 0.74 \n",
      "\n",
      "\n",
      "Confusion matrix data test XGB Base\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1    552    376\n",
      "Akt0    870   6440\n",
      "====================================================================================================\n",
      "Classification report data TRAIN XGB Base\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.90      0.85     29238\n",
      "           1       0.89      0.79      0.84     29238\n",
      "\n",
      "    accuracy                           0.85     58476\n",
      "   macro avg       0.85      0.85      0.85     58476\n",
      "weighted avg       0.85      0.85      0.85     58476\n",
      "\n",
      "\n",
      "ROC AUC train : 0.85 \n",
      "\n",
      "\n",
      "Confusion matrix data train XGB Base\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1  23185   6053\n",
      "Akt0   2904  26334\n"
     ]
    }
   ],
   "source": [
    "# Evaluation Matrix of XGBoost base model\n",
    "\n",
    "conf_mat(pipe_XGB, X_train_OS, X_test, y_train_OS, y_test, 'XGB Base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Base Models's Evaluation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LR_Base</th>\n",
       "      <th>KNN_Base</th>\n",
       "      <th>SVM_Base</th>\n",
       "      <th>DT_Base</th>\n",
       "      <th>RF_Base</th>\n",
       "      <th>XGB_Base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Precison</th>\n",
       "      <td>0.356336</td>\n",
       "      <td>0.271611</td>\n",
       "      <td>0.093219</td>\n",
       "      <td>0.306198</td>\n",
       "      <td>0.446784</td>\n",
       "      <td>0.388186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.645474</td>\n",
       "      <td>0.572198</td>\n",
       "      <td>0.798491</td>\n",
       "      <td>0.356681</td>\n",
       "      <td>0.411638</td>\n",
       "      <td>0.594828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           LR_Base  KNN_Base  SVM_Base   DT_Base   RF_Base  XGB_Base\n",
       "Precison  0.356336  0.271611  0.093219  0.306198  0.446784  0.388186\n",
       "Recall    0.645474  0.572198  0.798491  0.356681  0.411638  0.594828"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing the precision and recall of all base model\n",
    "\n",
    "prec_rec ([pipe_LR, pipe_KNN, pipe_SVM, pipe_DT, pipe_RF, pipe_XGB], X_test, y_test, ['LR_Base', 'KNN_Base', 'SVM_Base', 'DT_Base', 'RF_Base', 'XGB_Base'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __HYPERPARAMETER TUNING__\n",
    "\n",
    "we choose 4 potential models for hyperparameter tuning:\n",
    "- Logistic Regression\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the stratifiedKfold for cross validation in hyperparameter tuning\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/fine-tuning-a-classifier-in-scikit-learn-66e048c21e65"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HYPERPARAMETER TUNING LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Default Parameter__\n",
    "- 'algo__C': 1,\n",
    "- 'algo__class_weight': None,\n",
    "- 'algo__fit_intercept': True,\n",
    "- 'algo__penalty': 'l2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1st TUNING__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the Logistic regression parameter for the 1st hyperparameter tuning\n",
    "\n",
    "param_LR = {\n",
    "    'algo__C' : list(np.logspace(-4,1,10)) + [1.0],\n",
    "    'algo__class_weight' : [None, {0:.4, 1:.6}, {0:.3, 1:.7}, {0:.2, 1:.8}, {0:.1, 1:.9}],\n",
    "    'algo__fit_intercept' : [False, True],\n",
    "    'algo__penalty' : ['l1', 'l2', 'elasticnet', 'none']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using gridsearchcv method for hyperparameter tuning with precision score as a benchmark\n",
    "\n",
    "LR_GS = GridSearchCV(pipe_LR, param_LR, cv=skf, n_jobs=-1, verbose=1, scoring='precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 440 candidates, totalling 1320 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   11.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   37.4s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1320 out of 1320 | elapsed:  4.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[('prep',\n",
       "                                        ColumnTransformer(transformers=[('numeric',\n",
       "                                                                         Pipeline(steps=[('scaler',\n",
       "                                                                                          RobustScaler())]),\n",
       "                                                                         ['age',\n",
       "                                                                          'education',\n",
       "                                                                          'pdays',\n",
       "                                                                          'previous',\n",
       "                                                                          'cons.price.idx',\n",
       "                                                                          'cons.conf.idx',\n",
       "                                                                          'euribor3m',\n",
       "                                                                          'nr.employed',\n",
       "                                                                          'emp.var.rate']),\n",
       "                                                                        ('categorical',\n",
       "                                                                         Pipeline(steps=[('encode...\n",
       "             param_grid={'algo__C': [0.0001, 0.00035938136638046257,\n",
       "                                     0.001291549665014884, 0.004641588833612782,\n",
       "                                     0.016681005372000592, 0.05994842503189409,\n",
       "                                     0.21544346900318845, 0.7742636826811278,\n",
       "                                     2.782559402207126, 10.0, 1.0],\n",
       "                         'algo__class_weight': [None, {0: 0.4, 1: 0.6},\n",
       "                                                {0: 0.3, 1: 0.7},\n",
       "                                                {0: 0.2, 1: 0.8},\n",
       "                                                {0: 0.1, 1: 0.9}],\n",
       "                         'algo__fit_intercept': [False, True],\n",
       "                         'algo__penalty': ['l1', 'l2', 'elasticnet', 'none']},\n",
       "             scoring='precision', verbose=1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run hyperparameter tuning\n",
    "\n",
    "LR_GS.fit(X_train_OS, y_train_OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algo__C': 0.0001,\n",
       " 'algo__class_weight': None,\n",
       " 'algo__fit_intercept': True,\n",
       " 'algo__penalty': 'none'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the best combination of parameter that create the best precision score\n",
    "\n",
    "LR_GS.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Logistic regression model after tuning that have the best parameter\n",
    "\n",
    "LR_Tune = LR_GS.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('prep',\n",
       "                 ColumnTransformer(transformers=[('numeric',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   RobustScaler())]),\n",
       "                                                  ['age', 'education', 'pdays',\n",
       "                                                   'previous', 'cons.price.idx',\n",
       "                                                   'cons.conf.idx', 'euribor3m',\n",
       "                                                   'nr.employed',\n",
       "                                                   'emp.var.rate']),\n",
       "                                                 ('categorical',\n",
       "                                                  Pipeline(steps=[('encoder',\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  ['job', 'marital', 'default',\n",
       "                                                   'housing', 'loan', 'contact',\n",
       "                                                   'month', 'day_of_week',\n",
       "                                                   'poutcome'])])),\n",
       "                ('algo', LogisticRegression(C=0.0001, penalty='none'))])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run the model\n",
    "\n",
    "LR_Tune.fit(X_train_OS, y_train_OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report data TEST LR Tuning 1 best estimator\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.85      0.90      7310\n",
      "           1       0.35      0.64      0.46       928\n",
      "\n",
      "    accuracy                           0.83      8238\n",
      "   macro avg       0.65      0.75      0.68      8238\n",
      "weighted avg       0.88      0.83      0.85      8238\n",
      "\n",
      "\n",
      "ROC AUC test : 0.75 \n",
      "\n",
      "\n",
      "Confusion matrix data test LR Tuning 1 best estimator\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1    595    333\n",
      "Akt0   1082   6228\n",
      "====================================================================================================\n",
      "Classification report data TRAIN LR Tuning 1 best estimator\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.85      0.76     29238\n",
      "           1       0.81      0.62      0.70     29238\n",
      "\n",
      "    accuracy                           0.74     58476\n",
      "   macro avg       0.75      0.74      0.73     58476\n",
      "weighted avg       0.75      0.74      0.73     58476\n",
      "\n",
      "\n",
      "ROC AUC train : 0.74 \n",
      "\n",
      "\n",
      "Confusion matrix data train LR Tuning 1 best estimator\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1  18125  11113\n",
      "Akt0   4378  24860\n"
     ]
    }
   ],
   "source": [
    "# evaluation matrix of the model\n",
    "\n",
    "conf_mat(LR_Tune, X_train_OS, X_test, y_train_OS, y_test, 'LR Tuning 1 best estimator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2nd TUNING__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the Logistic regression parameter for the 2nd hyperparameter tuning\n",
    "\n",
    "param_LR2 = {\n",
    "    'algo__C' : np.logspace(-6,-3),\n",
    "    'algo__class_weight' : [None, {0:.4, 1:.6}, {0:.3, 1:.7}, {0:.2, 1:.8}, {0:.1, 1:.9}],\n",
    "    'algo__fit_intercept' : [False, True],\n",
    "    'algo__penalty' : ['l1', 'l2', 'elasticnet', 'none']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using gridsearchcv method for hyperparameter tuning with precision score as a benchmark\n",
    "\n",
    "LR_GS2 = GridSearchCV(pipe_LR, param_LR2, cv=skf, n_jobs=-1, verbose=1, scoring='precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2000 candidates, totalling 6000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   28.8s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:  8.3min\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed: 10.7min\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed: 13.6min\n",
      "[Parallel(n_jobs=-1)]: Done 6000 out of 6000 | elapsed: 16.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=False),\n",
       "             estimator=Pipeline(steps=[('prep',\n",
       "                                        ColumnTransformer(transformers=[('numeric',\n",
       "                                                                         Pipeline(steps=[('scaler',\n",
       "                                                                                          RobustScaler())]),\n",
       "                                                                         ['age',\n",
       "                                                                          'education',\n",
       "                                                                          'pdays',\n",
       "                                                                          'previous',\n",
       "                                                                          'cons.price.idx',\n",
       "                                                                          'cons.conf.idx',\n",
       "                                                                          'euribor3m',\n",
       "                                                                          'nr.employed',\n",
       "                                                                          'emp.var.rate']),\n",
       "                                                                        ('categorical',\n",
       "                                                                         Pipeline(steps=[('encode...\n",
       "       2.81176870e-04, 3.23745754e-04, 3.72759372e-04, 4.29193426e-04,\n",
       "       4.94171336e-04, 5.68986603e-04, 6.55128557e-04, 7.54312006e-04,\n",
       "       8.68511374e-04, 1.00000000e-03]),\n",
       "                         'algo__class_weight': [None, {0: 0.4, 1: 0.6},\n",
       "                                                {0: 0.3, 1: 0.7},\n",
       "                                                {0: 0.2, 1: 0.8},\n",
       "                                                {0: 0.1, 1: 0.9}],\n",
       "                         'algo__fit_intercept': [False, True],\n",
       "                         'algo__penalty': ['l1', 'l2', 'elasticnet', 'none']},\n",
       "             scoring='precision', verbose=1)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run hyperparameter tuning\n",
    "\n",
    "LR_GS2.fit(X_train_OS, y_train_OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algo__C': 1e-06,\n",
       " 'algo__class_weight': None,\n",
       " 'algo__fit_intercept': True,\n",
       " 'algo__penalty': 'l2'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the best combination of parameters that create the best precision score\n",
    "\n",
    "LR_GS2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Logistic regression model after tuning that have the best parameter\n",
    "\n",
    "LR_Tune2 = LR_GS2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('prep',\n",
       "                 ColumnTransformer(transformers=[('numeric',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   RobustScaler())]),\n",
       "                                                  ['age', 'education', 'pdays',\n",
       "                                                   'previous', 'cons.price.idx',\n",
       "                                                   'cons.conf.idx', 'euribor3m',\n",
       "                                                   'nr.employed',\n",
       "                                                   'emp.var.rate']),\n",
       "                                                 ('categorical',\n",
       "                                                  Pipeline(steps=[('encoder',\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  ['job', 'marital', 'default',\n",
       "                                                   'housing', 'loan', 'contact',\n",
       "                                                   'month', 'day_of_week',\n",
       "                                                   'poutcome'])])),\n",
       "                ('algo', LogisticRegression(C=1e-06))])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_Tune2.fit(X_train_OS, y_train_OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report data TEST LR Tuning 2 best estimator\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.94      7310\n",
      "           1       0.65      0.20      0.31       928\n",
      "\n",
      "    accuracy                           0.90      8238\n",
      "   macro avg       0.78      0.59      0.63      8238\n",
      "weighted avg       0.88      0.90      0.87      8238\n",
      "\n",
      "\n",
      "ROC AUC test : 0.59 \n",
      "\n",
      "\n",
      "Confusion matrix data test LR Tuning 2 best estimator\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1    187    741\n",
      "Akt0    102   7208\n",
      "====================================================================================================\n",
      "Classification report data TRAIN LR Tuning 2 best estimator\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.98      0.71     29238\n",
      "           1       0.93      0.21      0.34     29238\n",
      "\n",
      "    accuracy                           0.60     58476\n",
      "   macro avg       0.74      0.60      0.53     58476\n",
      "weighted avg       0.74      0.60      0.53     58476\n",
      "\n",
      "\n",
      "ROC AUC train : 0.6 \n",
      "\n",
      "\n",
      "Confusion matrix data train LR Tuning 2 best estimator\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1   6143  23095\n",
      "Akt0    446  28792\n"
     ]
    }
   ],
   "source": [
    "conf_mat(LR_Tune2, X_train_OS, X_test, y_train_OS, y_test, 'LR Tuning 2 best estimator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HYPERPARAMETER TUNING DECISION TREE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Default parameter__\n",
    "- 'algo__max_depth': None\n",
    "- 'algo__min_samples_leaf': 1\n",
    "- 'algo__max_features': None\n",
    "- 'algo__class_weight': None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1st TUNING__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the Decision tree parameter for the 1st hyperparameter tuning\n",
    "\n",
    "param_DT = {\n",
    "    'algo__max_depth': list(np.arange(0, 101, 5)) + [None],\n",
    "    'algo__min_samples_leaf': np.arange(1, 1000, 50),\n",
    "    'algo__max_features': [None, 0.2, 0.5, 0.8, 1],\n",
    "    'algo__class_weight': [None, {0:.4, 1:.6}, {0:.3, 1:.7}, {0:.2, 1:.8}]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using randomizedsearchcv method for hyperparameter tuning with precision score as a benchmark\n",
    "\n",
    "DT_RS = RandomizedSearchCV(pipe_DT, param_DT, cv=skf, n_iter=2000, n_jobs=-1, verbose=1, random_state=42, scoring='precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2000 candidates, totalling 6000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   22.8s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   58.5s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:  7.2min\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed:  8.9min\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed: 10.7min\n",
      "[Parallel(n_jobs=-1)]: Done 6000 out of 6000 | elapsed: 12.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=False),\n",
       "                   estimator=Pipeline(steps=[('prep',\n",
       "                                              ColumnTransformer(transformers=[('numeric',\n",
       "                                                                               Pipeline(steps=[('scaler',\n",
       "                                                                                                RobustScaler())]),\n",
       "                                                                               ['age',\n",
       "                                                                                'education',\n",
       "                                                                                'pdays',\n",
       "                                                                                'previous',\n",
       "                                                                                'cons.price.idx',\n",
       "                                                                                'cons.conf.idx',\n",
       "                                                                                'euribor3m',\n",
       "                                                                                'nr.employed',\n",
       "                                                                                'emp.var.rate']),\n",
       "                                                                              ('categorical',\n",
       "                                                                               Pipeline(steps=[('...\n",
       "                   param_distributions={'algo__class_weight': [None,\n",
       "                                                               {0: 0.4, 1: 0.6},\n",
       "                                                               {0: 0.3, 1: 0.7},\n",
       "                                                               {0: 0.2,\n",
       "                                                                1: 0.8}],\n",
       "                                        'algo__max_depth': [0, 5, 10, 15, 20,\n",
       "                                                            25, 30, 35, 40, 45,\n",
       "                                                            50, 55, 60, 65, 70,\n",
       "                                                            75, 80, 85, 90, 95,\n",
       "                                                            100, None],\n",
       "                                        'algo__max_features': [None, 0.2, 0.5,\n",
       "                                                               0.8, 1],\n",
       "                                        'algo__min_samples_leaf': array([  1,  51, 101, 151, 201, 251, 301, 351, 401, 451, 501, 551, 601,\n",
       "       651, 701, 751, 801, 851, 901, 951])},\n",
       "                   random_state=42, scoring='precision', verbose=1)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run hyperparameter tuning\n",
    "\n",
    "DT_RS.fit(X_train_OS, y_train_OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algo__min_samples_leaf': 1,\n",
       " 'algo__max_features': 0.8,\n",
       " 'algo__max_depth': 95,\n",
       " 'algo__class_weight': {0: 0.2, 1: 0.8}}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the best combination of parameters that create the best precision score\n",
    "\n",
    "DT_RS.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Decision tree model after tuning that have the best parameter\n",
    "\n",
    "DT_Tune = DT_RS.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('prep',\n",
       "                 ColumnTransformer(transformers=[('numeric',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   RobustScaler())]),\n",
       "                                                  ['age', 'education', 'pdays',\n",
       "                                                   'previous', 'cons.price.idx',\n",
       "                                                   'cons.conf.idx', 'euribor3m',\n",
       "                                                   'nr.employed',\n",
       "                                                   'emp.var.rate']),\n",
       "                                                 ('categorical',\n",
       "                                                  Pipeline(steps=[('encoder',\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  ['job', 'marital', 'default',\n",
       "                                                   'housing', 'loan', 'contact',\n",
       "                                                   'month', 'day_of_week',\n",
       "                                                   'poutcome'])])),\n",
       "                ('algo',\n",
       "                 DecisionTreeClassifier(class_weight={0: 0.2, 1: 0.8},\n",
       "                                        max_depth=95, max_features=0.8,\n",
       "                                        random_state=42))])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT_Tune.fit(X_train_OS, y_train_OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report data TEST DT Tuning 1 best estimator\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91      7310\n",
      "           1       0.32      0.33      0.33       928\n",
      "\n",
      "    accuracy                           0.85      8238\n",
      "   macro avg       0.62      0.62      0.62      8238\n",
      "weighted avg       0.85      0.85      0.85      8238\n",
      "\n",
      "\n",
      "ROC AUC test : 0.62 \n",
      "\n",
      "\n",
      "Confusion matrix data test DT Tuning 1 best estimator\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1    307    621\n",
      "Akt0    646   6664\n",
      "====================================================================================================\n",
      "Classification report data TRAIN DT Tuning 1 best estimator\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     29238\n",
      "           1       0.98      1.00      0.99     29238\n",
      "\n",
      "    accuracy                           0.99     58476\n",
      "   macro avg       0.99      0.99      0.99     58476\n",
      "weighted avg       0.99      0.99      0.99     58476\n",
      "\n",
      "\n",
      "ROC AUC train : 0.99 \n",
      "\n",
      "\n",
      "Confusion matrix data train DT Tuning 1 best estimator\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1  29238      0\n",
      "Akt0    452  28786\n"
     ]
    }
   ],
   "source": [
    "conf_mat(DT_Tune, X_train_OS, X_test, y_train_OS, y_test, 'DT Tuning 1 best estimator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2nd TUNING__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the Decision tree parameter for the 2nd hyperparameter tuning\n",
    "\n",
    "param_DT2 = {\n",
    "    'algo__max_depth': list(np.arange(50, 151, 5)) + [None],\n",
    "    'algo__min_samples_leaf': np.arange(1, 100, 10),\n",
    "    'algo__max_features': [None, 0.2, 0.5, 0.8, 1],\n",
    "    'algo__class_weight': [None, {0:.4, 1:.6}, {0:.3, 1:.7}, {0:.2, 1:.8}]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using randomizedsearchcv method for hyperparameter tuning with precision score as a benchmark\n",
    "\n",
    "DT_RS2 = RandomizedSearchCV(pipe_DT, param_DT2, cv=skf, n_iter=2000, n_jobs=-1, verbose=1, random_state=42, scoring='precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2000 candidates, totalling 6000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    4.4s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   21.5s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   48.9s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed: 10.1min\n",
      "[Parallel(n_jobs=-1)]: Done 6000 out of 6000 | elapsed: 12.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=False),\n",
       "                   estimator=Pipeline(steps=[('prep',\n",
       "                                              ColumnTransformer(transformers=[('numeric',\n",
       "                                                                               Pipeline(steps=[('scaler',\n",
       "                                                                                                RobustScaler())]),\n",
       "                                                                               ['age',\n",
       "                                                                                'education',\n",
       "                                                                                'pdays',\n",
       "                                                                                'previous',\n",
       "                                                                                'cons.price.idx',\n",
       "                                                                                'cons.conf.idx',\n",
       "                                                                                'euribor3m',\n",
       "                                                                                'nr.employed',\n",
       "                                                                                'emp.var.rate']),\n",
       "                                                                              ('categorical',\n",
       "                                                                               Pipeline(steps=[('...\n",
       "                   n_iter=2000, n_jobs=-1,\n",
       "                   param_distributions={'algo__class_weight': [None,\n",
       "                                                               {0: 0.4, 1: 0.6},\n",
       "                                                               {0: 0.3, 1: 0.7},\n",
       "                                                               {0: 0.2,\n",
       "                                                                1: 0.8}],\n",
       "                                        'algo__max_depth': [50, 55, 60, 65, 70,\n",
       "                                                            75, 80, 85, 90, 95,\n",
       "                                                            100, 105, 110, 115,\n",
       "                                                            120, 125, 130, 135,\n",
       "                                                            140, 145, 150,\n",
       "                                                            None],\n",
       "                                        'algo__max_features': [None, 0.2, 0.5,\n",
       "                                                               0.8, 1],\n",
       "                                        'algo__min_samples_leaf': array([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91])},\n",
       "                   random_state=42, scoring='precision', verbose=1)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run hyperparameter tuning\n",
    "\n",
    "DT_RS2.fit(X_train_OS, y_train_OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algo__min_samples_leaf': 1,\n",
       " 'algo__max_features': 0.8,\n",
       " 'algo__max_depth': 60,\n",
       " 'algo__class_weight': {0: 0.2, 1: 0.8}}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the best combination of parameters that create the best precision score\n",
    "\n",
    "DT_RS2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Decision tree model after tuning that have the best parameter\n",
    "\n",
    "DT_Tune2 = DT_RS2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('prep',\n",
       "                 ColumnTransformer(transformers=[('numeric',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   RobustScaler())]),\n",
       "                                                  ['age', 'education', 'pdays',\n",
       "                                                   'previous', 'cons.price.idx',\n",
       "                                                   'cons.conf.idx', 'euribor3m',\n",
       "                                                   'nr.employed',\n",
       "                                                   'emp.var.rate']),\n",
       "                                                 ('categorical',\n",
       "                                                  Pipeline(steps=[('encoder',\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  ['job', 'marital', 'default',\n",
       "                                                   'housing', 'loan', 'contact',\n",
       "                                                   'month', 'day_of_week',\n",
       "                                                   'poutcome'])])),\n",
       "                ('algo',\n",
       "                 DecisionTreeClassifier(class_weight={0: 0.2, 1: 0.8},\n",
       "                                        max_depth=60, max_features=0.8,\n",
       "                                        random_state=42))])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT_Tune2.fit(X_train_OS, y_train_OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report data TEST DT Tuning 2 best estimator\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91      7310\n",
      "           1       0.32      0.33      0.33       928\n",
      "\n",
      "    accuracy                           0.85      8238\n",
      "   macro avg       0.62      0.62      0.62      8238\n",
      "weighted avg       0.85      0.85      0.85      8238\n",
      "\n",
      "\n",
      "ROC AUC test : 0.62 \n",
      "\n",
      "\n",
      "Confusion matrix data test DT Tuning 2 best estimator\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1    307    621\n",
      "Akt0    646   6664\n",
      "====================================================================================================\n",
      "Classification report data TRAIN DT Tuning 2 best estimator\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     29238\n",
      "           1       0.98      1.00      0.99     29238\n",
      "\n",
      "    accuracy                           0.99     58476\n",
      "   macro avg       0.99      0.99      0.99     58476\n",
      "weighted avg       0.99      0.99      0.99     58476\n",
      "\n",
      "\n",
      "ROC AUC train : 0.99 \n",
      "\n",
      "\n",
      "Confusion matrix data train DT Tuning 2 best estimator\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1  29238      0\n",
      "Akt0    452  28786\n"
     ]
    }
   ],
   "source": [
    "conf_mat(DT_Tune2, X_train_OS, X_test, y_train_OS, y_test, 'DT Tuning 2 best estimator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HYPERPARAMETER TUNING RANDOM FOREST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Default__\n",
    "- 'algo__n_estimators': 100,\n",
    "- 'algo__max_depth': None,\n",
    "- 'algo__min_samples_leaf': 1,\n",
    "- 'algo__class_weight': None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1st TUNING__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the Random Forest parameter for the 1st hyperparameter tuning\n",
    "\n",
    "param_RF = {\n",
    "    'algo__n_estimators' : np.arange(100, 1000, 100),\n",
    "    'algo__max_depth' : list(np.arange(10, 100, 10)) + [None],\n",
    "    'algo__min_samples_leaf' : list(np.arange(10, 100, 10)) + [1],\n",
    "    'algo__class_weight' : [None, {0:.4, 1:.6}, {0:.3, 1:.7}, {0:.2, 1:.8}, {0:.15, 1: .85}, {0:.1, 1:.9}]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using randomizedsearchcv method for hyperparameter tuning with precision score as a benchmark\n",
    "\n",
    "RF_RS = RandomizedSearchCV(pipe_RF, param_RF, cv=skf, n_iter=200, n_jobs=-1, verbose=1, random_state=42, scoring='precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 200 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 19.6min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 155.9min\n",
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed: 176.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=False),\n",
       "                   estimator=Pipeline(steps=[('prep',\n",
       "                                              ColumnTransformer(transformers=[('numeric',\n",
       "                                                                               Pipeline(steps=[('scaler',\n",
       "                                                                                                RobustScaler())]),\n",
       "                                                                               ['age',\n",
       "                                                                                'education',\n",
       "                                                                                'pdays',\n",
       "                                                                                'previous',\n",
       "                                                                                'cons.price.idx',\n",
       "                                                                                'cons.conf.idx',\n",
       "                                                                                'euribor3m',\n",
       "                                                                                'nr.employed',\n",
       "                                                                                'emp.var.rate']),\n",
       "                                                                              ('categorical',\n",
       "                                                                               Pipeline(steps=[('...\n",
       "                   n_iter=200, n_jobs=-1,\n",
       "                   param_distributions={'algo__class_weight': [None,\n",
       "                                                               {0: 0.4, 1: 0.6},\n",
       "                                                               {0: 0.3, 1: 0.7},\n",
       "                                                               {0: 0.2, 1: 0.8},\n",
       "                                                               {0: 0.15,\n",
       "                                                                1: 0.85},\n",
       "                                                               {0: 0.1,\n",
       "                                                                1: 0.9}],\n",
       "                                        'algo__max_depth': [10, 20, 30, 40, 50,\n",
       "                                                            60, 70, 80, 90,\n",
       "                                                            None],\n",
       "                                        'algo__min_samples_leaf': [10, 20, 30,\n",
       "                                                                   40, 50, 60,\n",
       "                                                                   70, 80, 90,\n",
       "                                                                   1],\n",
       "                                        'algo__n_estimators': array([100, 200, 300, 400, 500, 600, 700, 800, 900])},\n",
       "                   random_state=42, scoring='precision', verbose=1)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run hyperparameter tuning\n",
    "\n",
    "RF_RS.fit(X_train_OS, y_train_OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algo__n_estimators': 100,\n",
       " 'algo__min_samples_leaf': 1,\n",
       " 'algo__max_depth': 90,\n",
       " 'algo__class_weight': {0: 0.2, 1: 0.8}}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the best combination of parameters that create the best precision score\n",
    "\n",
    "RF_RS.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Random Forest model after tuning that have the best parameter\n",
    "\n",
    "RF_Tune = RF_RS.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('prep',\n",
       "                 ColumnTransformer(transformers=[('numeric',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   RobustScaler())]),\n",
       "                                                  ['age', 'education', 'pdays',\n",
       "                                                   'previous', 'cons.price.idx',\n",
       "                                                   'cons.conf.idx', 'euribor3m',\n",
       "                                                   'nr.employed',\n",
       "                                                   'emp.var.rate']),\n",
       "                                                 ('categorical',\n",
       "                                                  Pipeline(steps=[('encoder',\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  ['job', 'marital', 'default',\n",
       "                                                   'housing', 'loan', 'contact',\n",
       "                                                   'month', 'day_of_week',\n",
       "                                                   'poutcome'])])),\n",
       "                ('algo',\n",
       "                 RandomForestClassifier(class_weight={0: 0.2, 1: 0.8},\n",
       "                                        max_depth=90, random_state=42))])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_Tune.fit(X_train_OS, y_train_OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report data TEST RF Tuning best estimator\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93      7310\n",
      "           1       0.45      0.41      0.43       928\n",
      "\n",
      "    accuracy                           0.88      8238\n",
      "   macro avg       0.69      0.67      0.68      8238\n",
      "weighted avg       0.87      0.88      0.87      8238\n",
      "\n",
      "\n",
      "ROC AUC test : 0.67 \n",
      "\n",
      "\n",
      "Confusion matrix data test RF Tuning best estimator\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1    379    549\n",
      "Akt0    471   6839\n",
      "====================================================================================================\n",
      "Classification report data TRAIN RF Tuning best estimator\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     29238\n",
      "           1       0.98      1.00      0.99     29238\n",
      "\n",
      "    accuracy                           0.99     58476\n",
      "   macro avg       0.99      0.99      0.99     58476\n",
      "weighted avg       0.99      0.99      0.99     58476\n",
      "\n",
      "\n",
      "ROC AUC train : 0.99 \n",
      "\n",
      "\n",
      "Confusion matrix data train RF Tuning best estimator\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1  29238      0\n",
      "Akt0    452  28786\n"
     ]
    }
   ],
   "source": [
    "conf_mat(RF_Tune, X_train_OS, X_test, y_train_OS, y_test, 'RF Tuning best estimator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2nd TUNING__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the Random Forest parameter for the 2nd hyperparameter tuning\n",
    "\n",
    "param_RF2 = {\n",
    "    'algo__n_estimators' : [10, 20, 30, 50, 80, 100],\n",
    "    'algo__max_depth' : [None, 1, 3, 5, 8, 10],\n",
    "    'algo__min_samples_leaf' : [1, 3, 5, 8, 10],\n",
    "    'algo__class_weight' : [None, {0:.4, 1:.6}, {0:.3, 1:.7}, {0:.2, 1:.8}, {0:.1, 1:.9}]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using randomizedsearchcv method for hyperparameter tuning with precision score as a benchmark\n",
    "\n",
    "RF_RS2 = RandomizedSearchCV(pipe_RF, param_RF2, cv=skf, n_iter=200, n_jobs=-1, verbose=1, random_state=42, scoring='precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 200 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   22.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed:  5.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=False),\n",
       "                   estimator=Pipeline(steps=[('prep',\n",
       "                                              ColumnTransformer(transformers=[('numeric',\n",
       "                                                                               Pipeline(steps=[('scaler',\n",
       "                                                                                                RobustScaler())]),\n",
       "                                                                               ['age',\n",
       "                                                                                'education',\n",
       "                                                                                'pdays',\n",
       "                                                                                'previous',\n",
       "                                                                                'cons.price.idx',\n",
       "                                                                                'cons.conf.idx',\n",
       "                                                                                'euribor3m',\n",
       "                                                                                'nr.employed',\n",
       "                                                                                'emp.var.rate']),\n",
       "                                                                              ('categorical',\n",
       "                                                                               Pipeline(steps=[('...\n",
       "                                                                                'poutcome'])])),\n",
       "                                             ('algo',\n",
       "                                              RandomForestClassifier(random_state=42))]),\n",
       "                   n_iter=200, n_jobs=-1,\n",
       "                   param_distributions={'algo__class_weight': [None,\n",
       "                                                               {0: 0.4, 1: 0.6},\n",
       "                                                               {0: 0.3, 1: 0.7},\n",
       "                                                               {0: 0.2, 1: 0.8},\n",
       "                                                               {0: 0.1,\n",
       "                                                                1: 0.9}],\n",
       "                                        'algo__max_depth': [None, 1, 3, 5, 8,\n",
       "                                                            10],\n",
       "                                        'algo__min_samples_leaf': [1, 3, 5, 8,\n",
       "                                                                   10],\n",
       "                                        'algo__n_estimators': [10, 20, 30, 50,\n",
       "                                                               80, 100]},\n",
       "                   random_state=42, scoring='precision', verbose=1)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run hyperparameter tuning\n",
    "\n",
    "RF_RS2.fit(X_train_OS, y_train_OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algo__n_estimators': 10,\n",
       " 'algo__min_samples_leaf': 1,\n",
       " 'algo__max_depth': None,\n",
       " 'algo__class_weight': {0: 0.3, 1: 0.7}}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the best combination of parameters that create the best precision score\n",
    "\n",
    "RF_RS2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Random Forest model after tuning that have the best parameter\n",
    "\n",
    "RF_Tune2 = RF_RS2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('prep',\n",
       "                 ColumnTransformer(transformers=[('numeric',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   RobustScaler())]),\n",
       "                                                  ['age', 'education', 'pdays',\n",
       "                                                   'previous', 'cons.price.idx',\n",
       "                                                   'cons.conf.idx', 'euribor3m',\n",
       "                                                   'nr.employed',\n",
       "                                                   'emp.var.rate']),\n",
       "                                                 ('categorical',\n",
       "                                                  Pipeline(steps=[('encoder',\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  ['job', 'marital', 'default',\n",
       "                                                   'housing', 'loan', 'contact',\n",
       "                                                   'month', 'day_of_week',\n",
       "                                                   'poutcome'])])),\n",
       "                ('algo',\n",
       "                 RandomForestClassifier(class_weight={0: 0.3, 1: 0.7},\n",
       "                                        n_estimators=10, random_state=42))])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_Tune2.fit(X_train_OS, y_train_OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report data TEST RF Tuning 2 best estimator\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93      7310\n",
      "           1       0.41      0.36      0.39       928\n",
      "\n",
      "    accuracy                           0.87      8238\n",
      "   macro avg       0.67      0.65      0.66      8238\n",
      "weighted avg       0.86      0.87      0.87      8238\n",
      "\n",
      "\n",
      "ROC AUC test : 0.65 \n",
      "\n",
      "\n",
      "Confusion matrix data test RF Tuning 2 best estimator\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1    334    594\n",
      "Akt0    473   6837\n",
      "====================================================================================================\n",
      "Classification report data TRAIN RF Tuning 2 best estimator\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     29238\n",
      "           1       0.98      1.00      0.99     29238\n",
      "\n",
      "    accuracy                           0.99     58476\n",
      "   macro avg       0.99      0.99      0.99     58476\n",
      "weighted avg       0.99      0.99      0.99     58476\n",
      "\n",
      "\n",
      "ROC AUC train : 0.99 \n",
      "\n",
      "\n",
      "Confusion matrix data train RF Tuning 2 best estimator\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1  29234      4\n",
      "Akt0    506  28732\n"
     ]
    }
   ],
   "source": [
    "conf_mat(RF_Tune2, X_train_OS, X_test, y_train_OS, y_test, 'RF Tuning 2 best estimator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3rd TUNING__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the Random Forest parameter for the 3rd hyperparameter tuning\n",
    "\n",
    "param_RF3 = {\n",
    "    'algo__n_estimators' : np.arange(60, 150, 20),\n",
    "    'algo__max_depth' : list(np.arange(50, 150, 20)) + [None],\n",
    "    'algo__min_samples_leaf' : np.arange(1, 10, 2),\n",
    "    'algo__class_weight' : [None, {0:.4, 1:.6}, {0:.3, 1:.7}, {0:.2, 1:.8}, {0:.15, 1: .85}]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using randomizedsearchcv method for hyperparameter tuning with precision score as a benchmark\n",
    "\n",
    "RF_RS3 = RandomizedSearchCV(pipe_RF, param_RF3, cv=skf, n_iter=200, n_jobs=-1, verbose=1, random_state=42, scoring='precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 200 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 13.7min\n",
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed: 18.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=False),\n",
       "                   estimator=Pipeline(steps=[('prep',\n",
       "                                              ColumnTransformer(transformers=[('numeric',\n",
       "                                                                               Pipeline(steps=[('scaler',\n",
       "                                                                                                RobustScaler())]),\n",
       "                                                                               ['age',\n",
       "                                                                                'education',\n",
       "                                                                                'pdays',\n",
       "                                                                                'previous',\n",
       "                                                                                'cons.price.idx',\n",
       "                                                                                'cons.conf.idx',\n",
       "                                                                                'euribor3m',\n",
       "                                                                                'nr.employed',\n",
       "                                                                                'emp.var.rate']),\n",
       "                                                                              ('categorical',\n",
       "                                                                               Pipeline(steps=[('...\n",
       "                                              RandomForestClassifier(random_state=42))]),\n",
       "                   n_iter=200, n_jobs=-1,\n",
       "                   param_distributions={'algo__class_weight': [None,\n",
       "                                                               {0: 0.4, 1: 0.6},\n",
       "                                                               {0: 0.3, 1: 0.7},\n",
       "                                                               {0: 0.2, 1: 0.8},\n",
       "                                                               {0: 0.15,\n",
       "                                                                1: 0.85}],\n",
       "                                        'algo__max_depth': [50, 70, 90, 110,\n",
       "                                                            130, None],\n",
       "                                        'algo__min_samples_leaf': array([1, 3, 5, 7, 9]),\n",
       "                                        'algo__n_estimators': array([ 60,  80, 100, 120, 140])},\n",
       "                   random_state=42, scoring='precision', verbose=1)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run hyperparameter tuning\n",
    "\n",
    "RF_RS3.fit(X_train_OS, y_train_OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algo__n_estimators': 60,\n",
       " 'algo__min_samples_leaf': 1,\n",
       " 'algo__max_depth': 90,\n",
       " 'algo__class_weight': {0: 0.15, 1: 0.85}}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the best combination of parameters that create the best precision score\n",
    "\n",
    "RF_RS3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Random Forest model after tuning that have the best parameter\n",
    "\n",
    "RF_Tune3 = RF_RS3.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('prep',\n",
       "                 ColumnTransformer(transformers=[('numeric',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   RobustScaler())]),\n",
       "                                                  ['age', 'education', 'pdays',\n",
       "                                                   'previous', 'cons.price.idx',\n",
       "                                                   'cons.conf.idx', 'euribor3m',\n",
       "                                                   'nr.employed',\n",
       "                                                   'emp.var.rate']),\n",
       "                                                 ('categorical',\n",
       "                                                  Pipeline(steps=[('encoder',\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  ['job', 'marital', 'default',\n",
       "                                                   'housing', 'loan', 'contact',\n",
       "                                                   'month', 'day_of_week',\n",
       "                                                   'poutcome'])])),\n",
       "                ('algo',\n",
       "                 RandomForestClassifier(class_weight={0: 0.15, 1: 0.85},\n",
       "                                        max_depth=90, n_estimators=60,\n",
       "                                        random_state=42))])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RF_Tune3.fit(X_train_OS, y_train_OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report data TEST RF Tuning 3 best estimator\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93      7310\n",
      "           1       0.43      0.39      0.41       928\n",
      "\n",
      "    accuracy                           0.87      8238\n",
      "   macro avg       0.68      0.66      0.67      8238\n",
      "weighted avg       0.87      0.87      0.87      8238\n",
      "\n",
      "\n",
      "ROC AUC test : 0.66 \n",
      "\n",
      "\n",
      "Confusion matrix data test RF Tuning 3 best estimator\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1    366    562\n",
      "Akt0    479   6831\n",
      "====================================================================================================\n",
      "Classification report data TRAIN RF Tuning 3 best estimator\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     29238\n",
      "           1       0.98      1.00      0.99     29238\n",
      "\n",
      "    accuracy                           0.99     58476\n",
      "   macro avg       0.99      0.99      0.99     58476\n",
      "weighted avg       0.99      0.99      0.99     58476\n",
      "\n",
      "\n",
      "ROC AUC train : 0.99 \n",
      "\n",
      "\n",
      "Confusion matrix data train RF Tuning 3 best estimator\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1  29238      0\n",
      "Akt0    452  28786\n"
     ]
    }
   ],
   "source": [
    "conf_mat(RF_Tune3, X_train_OS, X_test, y_train_OS, y_test, 'RF Tuning 3 best estimator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HYPERPARAMETER TUNING XGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__DEFAULT PARAMETER__\n",
    "\n",
    "1. 'algo__n_estimators': 100,\n",
    "2. 'algo__max_depth': 6,\n",
    "3. 'algo__learning_rate': 0.300000012,\n",
    "4. 'algo__gamma': 0,\n",
    "5. 'algo__colsample_bytree': 1,\n",
    "6. 'algo__subsample': 1,\n",
    "7. 'algo__reg_alpha': 0,\n",
    "8. 'algo__reg_lambda': 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1st Tuning__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the XGBoost parameter for the 1st hyperparameter tuning\n",
    "\n",
    "param_XGB = {\n",
    "    'algo__n_estimators' : np.arange(100, 600, 100),\n",
    "    'algo__max_depth' : [2, 3, 5, 6, 8, 10],\n",
    "    'algo__learning_rate' : list(np.logspace(-3, 0, 4)) + [0.300000012],\n",
    "    'algo__gamma' : np.logspace(-3, 2, 6)\n",
    "#     'algo__colsample_bytree' : [0.3, 0.5, 0.7, 0.8],\n",
    "#     'algo__subsample' : [0.3, 0.5, 0.7, 0.8],\n",
    "#     'algo__reg_alpha' : np.logspace(-3, 3, 7),\n",
    "#     'algo__reg_lambda' : np.logspace(-3, 3, 7)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using randomizedsearchcv method for hyperparameter tuning with precision score as a benchmark\n",
    "\n",
    "XGB_RS = RandomizedSearchCV(pipe_XGB, param_XGB, cv=skf, n_iter=200, n_jobs=-1, verbose=1, random_state=42, scoring='precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 200 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed: 28.4min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 65.1min\n",
      "[Parallel(n_jobs=-1)]: Done 600 out of 600 | elapsed: 93.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:57:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=StratifiedKFold(n_splits=3, random_state=None, shuffle=False),\n",
       "                   estimator=Pipeline(steps=[('prep',\n",
       "                                              ColumnTransformer(transformers=[('numeric',\n",
       "                                                                               Pipeline(steps=[('scaler',\n",
       "                                                                                                RobustScaler())]),\n",
       "                                                                               ['age',\n",
       "                                                                                'education',\n",
       "                                                                                'pdays',\n",
       "                                                                                'previous',\n",
       "                                                                                'cons.price.idx',\n",
       "                                                                                'cons.conf.idx',\n",
       "                                                                                'euribor3m',\n",
       "                                                                                'nr.employed',\n",
       "                                                                                'emp.var.rate']),\n",
       "                                                                              ('categorical',\n",
       "                                                                               Pipeline(steps=[('...\n",
       "                                                            tree_method='exact',\n",
       "                                                            validate_parameters=1,\n",
       "                                                            verbosity=None))]),\n",
       "                   n_iter=200, n_jobs=-1,\n",
       "                   param_distributions={'algo__gamma': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02]),\n",
       "                                        'algo__learning_rate': [0.001, 0.01,\n",
       "                                                                0.1, 1.0,\n",
       "                                                                0.300000012],\n",
       "                                        'algo__max_depth': [2, 3, 5, 6, 8, 10],\n",
       "                                        'algo__n_estimators': array([100, 200, 300, 400, 500])},\n",
       "                   random_state=42, scoring='precision', verbose=1)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run hyperparameter tuning\n",
    "\n",
    "XGB_RS.fit(X_train_OS, y_train_OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algo__n_estimators': 500,\n",
       " 'algo__max_depth': 10,\n",
       " 'algo__learning_rate': 0.300000012,\n",
       " 'algo__gamma': 0.01}"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the best combination of parameters that create the best precision score\n",
    "\n",
    "XGB_RS.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define XGBoost model after tuning that have the best parameter\n",
    "\n",
    "XGB_Tune = XGB_RS.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:05:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('prep',\n",
       "                 ColumnTransformer(transformers=[('numeric',\n",
       "                                                  Pipeline(steps=[('scaler',\n",
       "                                                                   RobustScaler())]),\n",
       "                                                  ['age', 'education', 'pdays',\n",
       "                                                   'previous', 'cons.price.idx',\n",
       "                                                   'cons.conf.idx', 'euribor3m',\n",
       "                                                   'nr.employed',\n",
       "                                                   'emp.var.rate']),\n",
       "                                                 ('categorical',\n",
       "                                                  Pipeline(steps=[('encoder',\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  ['job', 'marital', 'default',\n",
       "                                                   'housing', 'loan', 'contact',\n",
       "                                                   'month', 'd...\n",
       "                               colsample_bytree=1, gamma=0.01, gpu_id=-1,\n",
       "                               importance_type='gain',\n",
       "                               interaction_constraints='',\n",
       "                               learning_rate=0.300000012, max_delta_step=0,\n",
       "                               max_depth=10, min_child_weight=1, missing=nan,\n",
       "                               monotone_constraints='()', n_estimators=500,\n",
       "                               n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "                               subsample=1, tree_method='exact',\n",
       "                               validate_parameters=1, verbosity=None))])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB_Tune.fit(X_train_OS, y_train_OS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report data TEST XGB Tuning 1 best estimator\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.93      0.93      7310\n",
      "           1       0.41      0.40      0.40       928\n",
      "\n",
      "    accuracy                           0.87      8238\n",
      "   macro avg       0.67      0.66      0.66      8238\n",
      "weighted avg       0.87      0.87      0.87      8238\n",
      "\n",
      "\n",
      "ROC AUC test : 0.66 \n",
      "\n",
      "\n",
      "Confusion matrix data test XGB Tuning 1 best estimator\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1    370    558\n",
      "Akt0    536   6774\n",
      "====================================================================================================\n",
      "Classification report data TRAIN XGB Tuning 1 best estimator\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     29238\n",
      "           1       0.98      1.00      0.99     29238\n",
      "\n",
      "    accuracy                           0.99     58476\n",
      "   macro avg       0.99      0.99      0.99     58476\n",
      "weighted avg       0.99      0.99      0.99     58476\n",
      "\n",
      "\n",
      "ROC AUC train : 0.99 \n",
      "\n",
      "\n",
      "Confusion matrix data train XGB Tuning 1 best estimator\n",
      "\n",
      "\n",
      "      Pred1  Pred0\n",
      "Akt1  29228     10\n",
      "Akt0    451  28787\n"
     ]
    }
   ],
   "source": [
    "conf_mat(XGB_Tune, X_train_OS, X_test, y_train_OS, y_test, 'XGB Tuning 1 best estimator')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMPARING THE PRECISION OF ALL MODEL AFTER HYPERPARAMETER TUNING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "================================================================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input the model to def function Evaluation Matrix \n",
    "\n",
    "tabel_banding = prec_rec (\n",
    "    [pipe_LR, pipe_KNN, pipe_SVM, pipe_DT, pipe_RF, pipe_XGB, LR_Tune, LR_Tune2, DT_Tune, DT_Tune2, RF_Tune,\n",
    "     RF_Tune2, RF_Tune3, XGB_Tune],\n",
    "    X_test, y_test,\n",
    "    ['LR_Base', 'KNN_Base', 'SVM_Base', 'DT_Base', 'RF_Base', 'XGB_Base', 'LR_HPT_BE 1', 'LR_HPT_BE 2',\n",
    "     'DT_HPT_BE 1', 'DT_HPT_BE 2', 'RF_HPT_BE 1', 'RF_HPT_BE 2', 'RF_HPT_BE 3', 'XGB_HPT_BE 1']\n",
    ").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precison</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR_HPT_BE 2</th>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.201509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_Base</th>\n",
       "      <td>0.446784</td>\n",
       "      <td>0.411638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_HPT_BE 1</th>\n",
       "      <td>0.445882</td>\n",
       "      <td>0.408405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_HPT_BE 3</th>\n",
       "      <td>0.433136</td>\n",
       "      <td>0.394397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF_HPT_BE 2</th>\n",
       "      <td>0.413879</td>\n",
       "      <td>0.359914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Precison    Recall\n",
       "LR_HPT_BE 2  0.647059  0.201509\n",
       "RF_Base      0.446784  0.411638\n",
       "RF_HPT_BE 1  0.445882  0.408405\n",
       "RF_HPT_BE 3  0.433136  0.394397\n",
       "RF_HPT_BE 2  0.413879  0.359914"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create table that show 5 model with the best precision \n",
    "\n",
    "tabel_banding = tabel_banding.sort_values(by='Precison', ascending=False)\n",
    "tabel_banding.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONCLUSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We use Logistic Regression (after the 2nd Hyperparameter tuning) with precison : 0.65 and recall : 0.2'"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"We use Logistic Regression (after the 2nd Hyperparameter tuning) with precison : {(round(tabel_banding['Precison'][0], 2))} and recall : {(round(tabel_banding['Recall'][0], 2))}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUGGESTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to add __costumer account balance__ feature that have greater impact to the model because before someone decide to take/buy a deposit, they surely gonna check their account balance first to see if they have enough money or not  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__all_data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 984,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the table/dataframe for all data\n",
    "\n",
    "df_all = pd.concat([X, y], axis=1)\n",
    "df_all = df_all.reset_index()\n",
    "df_all = df_all.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 985,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict all people (in test data) that gonna take the deposit or not\n",
    "\n",
    "y_all_predict = LR_Tune2.predict(X)\n",
    "df_all['y_predict LR'] = y_all_predict # create new column for y predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1009,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>y_predict LR</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36000</td>\n",
       "      <td>548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3673</td>\n",
       "      <td>967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "y_predict LR      0    1\n",
       "y                       \n",
       "0             36000  548\n",
       "1              3673  967"
      ]
     },
     "execution_count": 1009,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing confusion matrix\n",
    "\n",
    "pd.crosstab(index=df_all['y'], columns = df_all['y_predict LR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1005,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Make a Bar Graph for Amount of each Values in Prediction Column\n",
    "\n",
    "plt.figure(figsize=(5,8))\n",
    "ax = sns.countplot(x=\"y_predict LR\", data=df_all)\n",
    "ax.set_title('Amount of each Values in y_predict LR', fontsize=15)\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'\\n{p.get_height()}', (p.get_x()+.25, p.get_height()), \n",
    "                size=15\n",
    "               )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICT PROBA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__all_data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1006,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the probability of one person to take the deposit or not\n",
    "\n",
    "y_all_predictproba = LR_Tune2.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1007,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input the data to df_all\n",
    "\n",
    "df_all_predictproba = pd.DataFrame(y_all_predictproba) # create new dataframe for prediction of the probability\n",
    "df_all_predictproba = df_all_predictproba.rename(columns={0: \"predict_proba LR 0\", 1: \"predict_proba LR 1\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1008,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine df_all with df that contain prediction of the probability\n",
    "\n",
    "df_all = pd.concat([df_all, df_all_predictproba], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1010,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Showing the distribution of probability of buying the deposit for each people\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.hist(df_all['predict_proba LR 1'], bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1011,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binning the probability of buying the deposit for each people\n",
    "\n",
    "proba1_bin = [-1,0.3,0.6,df_all['predict_proba LR 1'].max()]\n",
    "label_proba1 = ['< 0.3', '0.3 - 0.6', '> 0.6']\n",
    "df_all['proba1_bin'] = pd.cut(df_all['predict_proba LR 1'], bins=proba1_bin, labels=label_proba1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1019,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Make a Bar Graph for Amount of each Values in group of Porbability 1 column for every value in Predict column (y_predict)\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "ax = sns.countplot(x=\"proba1_bin\", hue=\"y_predict LR\", data=df_all)\n",
    "ax.set_title('Amount of each Values in group of Porbability 1 for each value in y_predict LR', fontsize=20)\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'\\n{p.get_height()}', (p.get_x()+.1, p.get_height()+500), \n",
    "                size=18\n",
    "               )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1020,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________\n",
    "__Simulation__\n",
    "_______________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___1st SIMULATION (SUM DURATION APPROACH)___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Assume__ : \n",
    "- all df data is new data\n",
    "- Cost driven by two main things : __Call Charges per Minutes__, __Salary__\n",
    "- The campaign duration is can be adjust\n",
    "- __call charges__ : 0.3 euro per minutes\n",
    "https://www.lonelyplanet.com/portugal/narratives/practical-information/directory/telephone#:~:text=Local%2C%20Regional%20%26%20National%20Calls&text=Local%20calls%20cost%20around%20%E2%82%AC,from%20anywhere%20in%20the%20country.\n",
    "\n",
    "- __Salary__ : 1600 euro/person/month\n",
    "http://www.salaryexplorer.com/salary-survey.php?loc=174&loctype=1&job=12702&jobtype=3\n",
    "\n",
    "- 4 hours/240 minutes of call that can handled by 1 employee per day "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1042,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x540 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,7.5))\n",
    "ax = sns.countplot(x=\"proba1_bin\", hue=\"y\", data=df_all)\n",
    "ax.set_title('Amount of each Values in group of Porbability 1 for each value in y actual\\n', fontsize=18)\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'\\n{p.get_height()}', (p.get_x()+.009, p.get_height()+500), \n",
    "                size=15\n",
    "               )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the model simulation (thershold :0.3 and 0.6) :\n",
    "- people that have probability to buy a deposit < 0.3 = 0\n",
    "- people that have probability to buy a deposit between 0.3 & 0.6 = 39673\n",
    "- people that have probability to buy a deposit > 0.6 = 1515\n",
    "\n",
    "If we assume for people that have bank account more than 30,000 Euro (from total people that have probability to buy a deposit between 0.3 & 0.6) is people that buy the deposit in actual (`df_all[(df_all['proba1_bin'] == '0.3 - 0.6') & (df_all['y'] == 1)]`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1022,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2698619"
      ]
     },
     "execution_count": 1022,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total duration after modelling\n",
    "\n",
    "df_all['duration'] = df['duration'] # adding column duration to df_all\n",
    "td_after = (df_all[(df_all['proba1_bin'] == '0.3 - 0.6') & (df_all['y'] == 1)]['duration'].sum()) + df_all[(df_all['proba1_bin'] == '> 0.6')]['duration'].sum()\n",
    "# extracting the sum of duration\n",
    "\n",
    "td_after # show the duration after using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1023,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 1023,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# employee needed after modelling\n",
    "\n",
    "round(((td_after/(20*3) # find the duration per days from 20 working days per month if the project take 2 months to finish\n",
    "       )/60 # convert the duration from second to minutes\n",
    "      )/240 # if one person have onle 4 hours or 240 minutes time to do telemarketing per day\n",
    "      , 0) # round up the numbers into 0 digit after comma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1024,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Cost simulation after modelling\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>total for all months</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Call Charges</th>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>44977</td>\n",
       "      <td>13493.094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Salary</th>\n",
       "      <td>1600</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>14400.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>Total</td>\n",
       "      <td>Total</td>\n",
       "      <td>Total</td>\n",
       "      <td>27893.094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Price Quantity Frequency  total for all months\n",
       "Call Charges    0.3        1     44977             13493.094\n",
       "Salary         1600        3         3             14400.000\n",
       "Total         Total    Total     Total             27893.094"
      ]
     },
     "execution_count": 1024,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data={\n",
    "    'Price' :{\n",
    "        'Call Charges' :  0.3, # 0.3 euro per minutes for call charges\n",
    "        'Salary' : 1600 # 1600 euro per month per person for telemarketing salary\n",
    "    },\n",
    "    'Quantity' :{\n",
    "        'Call Charges' :  1, #\n",
    "        'Salary' : 3 # 3 employee for the campaign\n",
    "    },\n",
    "    'Frequency' : {\n",
    "        'Call Charges' :  round(td_after/60, 2), # the duration of call (in minutes) that required after using the model\n",
    "        'Salary' : 3 # 3 months to finish the campaign\n",
    "    }\n",
    "}\n",
    "\n",
    "print('Table Cost simulation after modelling')\n",
    "after1 = pd.DataFrame(data)\n",
    "after1['total for all months'] = after1['Price']*after1['Quantity']*after1['Frequency'] # adding columns that contain total cost \n",
    "# that we needed for a certain sector in 2 months\n",
    "\n",
    "total_after1 = {\n",
    "    'Price': 'Total',\n",
    "    'Quantity' : 'Total',\n",
    "    'Frequency' : 'Total',\n",
    "    'total for all months' : after1['total for all months'].sum()\n",
    "} # make new dictionary that have he sum of total cost for all sector in 2 months\n",
    "\n",
    "new_row1 = pd.Series(total_after1, name='Total') # make a series of the dict\n",
    "after1 = after1.append(new_row1) # make a new row\n",
    "after1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1025,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "177304.05"
      ]
     },
     "execution_count": 1025,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total duration before\n",
    "\n",
    "(df_all['duration'].sum())/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1026,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 1026,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# emp needed before\n",
    "\n",
    "round(((df_all['duration'].sum()/(20*10) # find the duration per days from 20 working days per month if the project\n",
    "        # take 10 months to finish\n",
    "       )/60 # convert the duration from second to minutes\n",
    "      )/240, # if one person have onle 4 hours or 240 minutes time to do telemarketing per day\n",
    "      0) # round up the numbers into 0 digit after comma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1027,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Cost simulation before modelling\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>total for all months</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Call Charges</th>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>177304</td>\n",
       "      <td>53191.215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Salary</th>\n",
       "      <td>1600</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>64000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>Total</td>\n",
       "      <td>Total</td>\n",
       "      <td>Total</td>\n",
       "      <td>117191.215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Price Quantity Frequency  total for all months\n",
       "Call Charges    0.3        1    177304             53191.215\n",
       "Salary         1600        4        10             64000.000\n",
       "Total         Total    Total     Total            117191.215"
      ]
     },
     "execution_count": 1027,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2={\n",
    "    'Price' :{\n",
    "        'Call Charges' :  0.3, # 0.3 euro per minutes for call charges\n",
    "        'Salary' : 1600 # 1600 euro per month per person for telemarketing salary\n",
    "    },\n",
    "    'Quantity' :{\n",
    "        'Call Charges' :  1, #\n",
    "        'Salary' : 4 # 4 employee for the campaign\n",
    "    },\n",
    "    'Frequency' : {\n",
    "        'Call Charges' :  (df_all['duration'].sum())/60, # the duration of call (in minutes) that required Before using the model\n",
    "        'Salary' : 10 # 10 months to finish the campaign\n",
    "    }\n",
    "}\n",
    "\n",
    "print('Table Cost simulation before modelling')\n",
    "before1 = pd.DataFrame(data2)\n",
    "before1['total for all months'] = before1['Price']*before1['Quantity']*before1['Frequency']# adding columns that contain\n",
    "# total cost that we needed for a certain sector in 2 months\n",
    "\n",
    "total_before1 = {\n",
    "    'Price': 'Total',\n",
    "    'Quantity' : 'Total',\n",
    "    'Frequency' : 'Total',\n",
    "    'total for all months' : before1['total for all months'].sum()\n",
    "}# make new dictionary that have he sum of total cost for all sector in 10 months\n",
    "\n",
    "new_row2 = pd.Series(total_before1, name='Total')# make a series of the dict\n",
    "before1 = before1.append(new_row2)# make a new row\n",
    "before1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined the Simulation Table Before and After Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1028,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>total for all months</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Before</th>\n",
       "      <th>Call Charges</th>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>177304</td>\n",
       "      <td>53191.215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Salary</th>\n",
       "      <td>1600</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>64000.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>Total</td>\n",
       "      <td>Total</td>\n",
       "      <td>Total</td>\n",
       "      <td>117191.215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">After</th>\n",
       "      <th>Call Charges</th>\n",
       "      <td>0.3</td>\n",
       "      <td>1</td>\n",
       "      <td>44977</td>\n",
       "      <td>13493.094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Salary</th>\n",
       "      <td>1600</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>14400.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>Total</td>\n",
       "      <td>Total</td>\n",
       "      <td>Total</td>\n",
       "      <td>27893.094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Price Quantity Frequency  total for all months\n",
       "Before Call Charges    0.3        1    177304             53191.215\n",
       "       Salary         1600        4        10             64000.000\n",
       "       Total         Total    Total     Total            117191.215\n",
       "After  Call Charges    0.3        1     44977             13493.094\n",
       "       Salary         1600        3         3             14400.000\n",
       "       Total         Total    Total     Total             27893.094"
      ]
     },
     "execution_count": 1028,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result1 = pd.concat([before1, after1], keys=[\"Before\", \"After\"])\n",
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1029,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after using the model can be more efficient up to 89298.121 euro saving, 76.2% decline\n"
     ]
    }
   ],
   "source": [
    "saving1= result1.loc['Before', 'Total']['total for all months']-result1.loc['After', 'Total']['total for all months']\n",
    "# extract the total cost before and after the modelling\n",
    "\n",
    "string1 = f\"Cost after using the model can be more efficient up to {saving1} euro saving,\" # show the amount of cost saving\n",
    "string2 = f\"{round((saving1/result1.loc['Before', 'Total']['total for all months'])*100, 2)}% decline\" # show the cost reduction\n",
    "\n",
    "print(string1, string2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________\n",
    "__Export Model__\n",
    "_______________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1031,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(LR_Tune2, 'Model_LR.jbl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
